entries: [
    # {description: "mmlu:subject=anatomy,model=groq/llama3-8b-8192", priority: 1}
    # {description: "mmlu:subject=abstract_algebra,model=groq/llama3-8b-8192", priority: 1}

    {description: "mmlu:model=groq/llama3-8b-8192,subject=abstract_algebra,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=abstract_algebra,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=abstract_algebra,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=anatomy,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=anatomy,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=anatomy,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_chemistry,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_chemistry,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_chemistry,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=computer_security,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=computer_security,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=computer_security,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=econometrics,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=econometrics,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=econometrics,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=global_facts,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=global_facts,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=global_facts,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=jurisprudence,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=jurisprudence,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=jurisprudence,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=philosophy,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=philosophy,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=philosophy,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=professional_medicine,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=professional_medicine,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=professional_medicine,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=us_foreign_policy,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=us_foreign_policy,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=us_foreign_policy,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=astronomy,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=astronomy,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=astronomy,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=business_ethics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=business_ethics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=business_ethics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=clinical_knowledge,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=clinical_knowledge,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=clinical_knowledge,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_biology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_biology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_biology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_computer_science,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_computer_science,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_computer_science,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_mathematics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_mathematics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_mathematics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_medicine,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_medicine,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_medicine,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_physics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_physics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=college_physics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=conceptual_physics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=conceptual_physics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=conceptual_physics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=electrical_engineering,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=electrical_engineering,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=electrical_engineering,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=elementary_mathematics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=elementary_mathematics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=elementary_mathematics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=formal_logic,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=formal_logic,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=formal_logic,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_biology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_biology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_biology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_chemistry,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_chemistry,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_chemistry,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_computer_science,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_computer_science,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_computer_science,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_european_history,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_european_history,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_european_history,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_geography,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_geography,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_geography,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_government_and_politics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_government_and_politics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_government_and_politics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_macroeconomics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_macroeconomics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_macroeconomics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_mathematics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_mathematics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_mathematics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_microeconomics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_microeconomics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_microeconomics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_physics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_physics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_physics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_psychology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_psychology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_psychology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_statistics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_statistics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_statistics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_us_history,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_us_history,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_us_history,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_world_history,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_world_history,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=high_school_world_history,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=human_aging,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=human_aging,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=human_aging,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=human_sexuality,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=human_sexuality,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=human_sexuality,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=international_law,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=international_law,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=international_law,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=logical_fallacies,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=logical_fallacies,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=logical_fallacies,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=machine_learning,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=machine_learning,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=machine_learning,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=management,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=management,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=management,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=marketing,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=marketing,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=marketing,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=medical_genetics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=medical_genetics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=medical_genetics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=miscellaneous,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=miscellaneous,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=miscellaneous,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=moral_disputes,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=moral_disputes,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=moral_disputes,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=moral_scenarios,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=moral_scenarios,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=moral_scenarios,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=nutrition,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=nutrition,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=nutrition,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=prehistory,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=prehistory,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=prehistory,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=professional_accounting,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=professional_accounting,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=professional_accounting,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=professional_law,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=professional_law,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=professional_law,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=professional_psychology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=professional_psychology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=professional_psychology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=public_relations,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=public_relations,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=public_relations,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=security_studies,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=security_studies,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=security_studies,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=sociology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=sociology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=sociology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=virology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=virology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=virology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=world_religions,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=world_religions,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-8b-8192,subject=world_religions,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}

    {description: "mmlu:model=groq/llama3-70b-8192,subject=abstract_algebra,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=abstract_algebra,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=abstract_algebra,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=anatomy,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=anatomy,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=anatomy,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_chemistry,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_chemistry,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_chemistry,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=computer_security,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=computer_security,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=computer_security,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=econometrics,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=econometrics,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=econometrics,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=global_facts,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=global_facts,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=global_facts,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=jurisprudence,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=jurisprudence,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=jurisprudence,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=philosophy,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=philosophy,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=philosophy,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=professional_medicine,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=professional_medicine,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=professional_medicine,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=us_foreign_policy,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=us_foreign_policy,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=us_foreign_policy,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=astronomy,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=astronomy,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=astronomy,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=business_ethics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=business_ethics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=business_ethics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=clinical_knowledge,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=clinical_knowledge,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=clinical_knowledge,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_biology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_biology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_biology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_computer_science,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_computer_science,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_computer_science,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_mathematics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_mathematics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_mathematics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_medicine,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_medicine,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_medicine,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_physics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_physics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=college_physics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=conceptual_physics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=conceptual_physics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=conceptual_physics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=electrical_engineering,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=electrical_engineering,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=electrical_engineering,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=elementary_mathematics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=elementary_mathematics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=elementary_mathematics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=formal_logic,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=formal_logic,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=formal_logic,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_biology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_biology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_biology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_chemistry,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_chemistry,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_chemistry,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_computer_science,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_computer_science,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_computer_science,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_european_history,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_european_history,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_european_history,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_geography,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_geography,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_geography,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_government_and_politics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_government_and_politics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_government_and_politics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_macroeconomics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_macroeconomics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_macroeconomics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_mathematics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_mathematics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_mathematics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_microeconomics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_microeconomics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_microeconomics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_physics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_physics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_physics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_psychology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_psychology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_psychology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_statistics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_statistics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_statistics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_us_history,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_us_history,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_us_history,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_world_history,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_world_history,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=high_school_world_history,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=human_aging,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=human_aging,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=human_aging,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=human_sexuality,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=human_sexuality,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=human_sexuality,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=international_law,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=international_law,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=international_law,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=logical_fallacies,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=logical_fallacies,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=logical_fallacies,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=machine_learning,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=machine_learning,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=machine_learning,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=management,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=management,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=management,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=marketing,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=marketing,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=marketing,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=medical_genetics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=medical_genetics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=medical_genetics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=miscellaneous,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=miscellaneous,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=miscellaneous,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=moral_disputes,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=moral_disputes,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=moral_disputes,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=moral_scenarios,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=moral_scenarios,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=moral_scenarios,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=nutrition,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=nutrition,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=nutrition,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=prehistory,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=prehistory,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=prehistory,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=professional_accounting,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=professional_accounting,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=professional_accounting,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=professional_law,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=professional_law,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=professional_law,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=professional_psychology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=professional_psychology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=professional_psychology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=public_relations,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=public_relations,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=public_relations,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=security_studies,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=security_studies,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=security_studies,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=sociology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=sociology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=sociology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=virology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=virology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=virology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=world_religions,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=world_religions,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=groq/llama3-70b-8192,subject=world_religions,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}


    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=abstract_algebra,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=abstract_algebra,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=abstract_algebra,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=anatomy,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=anatomy,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=anatomy,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_chemistry,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_chemistry,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_chemistry,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=computer_security,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=computer_security,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=computer_security,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=econometrics,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=econometrics,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=econometrics,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=global_facts,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=global_facts,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=global_facts,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=jurisprudence,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=jurisprudence,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=jurisprudence,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=philosophy,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=philosophy,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=philosophy,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=professional_medicine,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=professional_medicine,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=professional_medicine,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=us_foreign_policy,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=us_foreign_policy,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=us_foreign_policy,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=astronomy,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=astronomy,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=astronomy,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=business_ethics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=business_ethics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=business_ethics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=clinical_knowledge,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=clinical_knowledge,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=clinical_knowledge,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_biology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_biology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_biology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_computer_science,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_computer_science,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_computer_science,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_mathematics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_mathematics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_mathematics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_medicine,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_medicine,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_medicine,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_physics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_physics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=college_physics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=conceptual_physics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=conceptual_physics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=conceptual_physics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=electrical_engineering,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=electrical_engineering,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=electrical_engineering,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=elementary_mathematics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=elementary_mathematics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=elementary_mathematics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=formal_logic,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=formal_logic,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=formal_logic,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_biology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_biology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_biology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_chemistry,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_chemistry,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_chemistry,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_computer_science,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_computer_science,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_computer_science,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_european_history,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_european_history,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_european_history,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_geography,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_geography,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_geography,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_government_and_politics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_government_and_politics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_government_and_politics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_macroeconomics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_macroeconomics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_macroeconomics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_mathematics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_mathematics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_mathematics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_microeconomics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_microeconomics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_microeconomics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_physics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_physics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_physics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_psychology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_psychology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_psychology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_statistics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_statistics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_statistics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_us_history,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_us_history,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_us_history,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_world_history,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_world_history,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=high_school_world_history,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=human_aging,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=human_aging,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=human_aging,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=human_sexuality,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=human_sexuality,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=human_sexuality,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=international_law,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=international_law,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=international_law,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=logical_fallacies,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=logical_fallacies,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=logical_fallacies,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=machine_learning,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=machine_learning,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=machine_learning,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=management,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=management,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=management,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=marketing,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=marketing,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=marketing,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=medical_genetics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=medical_genetics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=medical_genetics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=miscellaneous,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=miscellaneous,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=miscellaneous,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=moral_disputes,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=moral_disputes,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=moral_disputes,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=moral_scenarios,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=moral_scenarios,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=moral_scenarios,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=nutrition,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=nutrition,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=nutrition,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=prehistory,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=prehistory,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=prehistory,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=professional_accounting,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=professional_accounting,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=professional_accounting,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=professional_law,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=professional_law,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=professional_law,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=professional_psychology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=professional_psychology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=professional_psychology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=public_relations,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=public_relations,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=public_relations,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=security_studies,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=security_studies,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=security_studies,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=sociology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=sociology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=sociology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=virology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=virology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=virology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=world_religions,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=world_religions,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-8b-chat-hf,subject=world_religions,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}


    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=abstract_algebra,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=abstract_algebra,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=abstract_algebra,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=anatomy,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=anatomy,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=anatomy,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_chemistry,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_chemistry,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_chemistry,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=computer_security,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=computer_security,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=computer_security,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=econometrics,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=econometrics,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=econometrics,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=global_facts,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=global_facts,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=global_facts,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=jurisprudence,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=jurisprudence,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=jurisprudence,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=philosophy,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=philosophy,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=philosophy,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=professional_medicine,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=professional_medicine,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=professional_medicine,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=us_foreign_policy,method=multiple_choice_joint", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=us_foreign_policy,method=multiple_choice_separate_original", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=us_foreign_policy,method=multiple_choice_separate_calibrated", priority: 1, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=astronomy,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=astronomy,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=astronomy,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=business_ethics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=business_ethics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=business_ethics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=clinical_knowledge,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=clinical_knowledge,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=clinical_knowledge,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_biology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_biology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_biology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_computer_science,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_computer_science,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_computer_science,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_mathematics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_mathematics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_mathematics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_medicine,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_medicine,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_medicine,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_physics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_physics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=college_physics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=conceptual_physics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=conceptual_physics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=conceptual_physics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=electrical_engineering,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=electrical_engineering,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=electrical_engineering,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=elementary_mathematics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=elementary_mathematics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=elementary_mathematics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=formal_logic,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=formal_logic,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=formal_logic,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_biology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_biology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_biology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_chemistry,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_chemistry,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_chemistry,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_computer_science,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_computer_science,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_computer_science,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_european_history,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_european_history,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_european_history,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_geography,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_geography,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_geography,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_government_and_politics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_government_and_politics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_government_and_politics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_macroeconomics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_macroeconomics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_macroeconomics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_mathematics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_mathematics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_mathematics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_microeconomics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_microeconomics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_microeconomics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_physics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_physics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_physics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_psychology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_psychology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_psychology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_statistics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_statistics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_statistics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_us_history,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_us_history,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_us_history,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_world_history,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_world_history,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=high_school_world_history,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=human_aging,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=human_aging,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=human_aging,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=human_sexuality,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=human_sexuality,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=human_sexuality,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=international_law,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=international_law,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=international_law,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=logical_fallacies,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=logical_fallacies,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=logical_fallacies,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=machine_learning,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=machine_learning,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=machine_learning,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=management,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=management,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=management,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=marketing,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=marketing,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=marketing,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=medical_genetics,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=medical_genetics,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=medical_genetics,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=miscellaneous,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=miscellaneous,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=miscellaneous,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=moral_disputes,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=moral_disputes,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=moral_disputes,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=moral_scenarios,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=moral_scenarios,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=moral_scenarios,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=nutrition,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=nutrition,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=nutrition,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=prehistory,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=prehistory,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=prehistory,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=professional_accounting,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=professional_accounting,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=professional_accounting,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=professional_law,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=professional_law,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=professional_law,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=professional_psychology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=professional_psychology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=professional_psychology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=public_relations,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=public_relations,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=public_relations,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=security_studies,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=security_studies,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=security_studies,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=sociology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=sociology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=sociology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=virology,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=virology,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=virology,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=world_religions,method=multiple_choice_joint", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=world_religions,method=multiple_choice_separate_original", priority: 3, groups: ["ablation_multiple_choice"]}
    {description: "mmlu:model=together/Llama-3-70b-chat-hf,subject=world_religions,method=multiple_choice_separate_calibrated", priority: 3, groups: ["ablation_multiple_choice"]}
        

    # {description: "mmlu:subject=anatomy,model=together/Llama-3-8b-chat-hf", priority: 1}
    # {description: "mmlu:subject=abstract_algebra,model=together/Llama-3-8b-chat-hf", priority: 1}

    # {description: "mmlu:subject=anatomy,model=together/Llama-3-70b-chat-hf", priority: 1}
    # {description: "mmlu:subject=abstract_algebra,model=together/Llama-3-70b-chat-hf", priority: 1}

#   {description: "mmlu:subject=anatomy,model=cohere/command", priority: 1}
    # {description: "mmlu:subject=anatomy,model=together/Llama-3-8b-chat-hf", priority: 1}
]