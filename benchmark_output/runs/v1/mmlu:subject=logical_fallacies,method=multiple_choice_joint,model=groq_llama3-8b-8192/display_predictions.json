[
  {
    "instance_id": "id88",
    "train_trial_index": 0,
    "predicted_text": "A",
    "base64_images": [],
    "mapped_output": "appeal to force",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 460.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 1.0
    }
  },
  {
    "instance_id": "id12",
    "train_trial_index": 0,
    "predicted_text": "A",
    "base64_images": [],
    "mapped_output": "Equivocation",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 466.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  },
  {
    "instance_id": "id66",
    "train_trial_index": 0,
    "predicted_text": "D",
    "base64_images": [],
    "mapped_output": "arguing an action should be taken based only on the need to be loyal to someone or to a group",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 548.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  },
  {
    "instance_id": "id181",
    "train_trial_index": 0,
    "predicted_text": "D",
    "base64_images": [],
    "mapped_output": "Hasty Generalization",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 459.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  },
  {
    "instance_id": "id142",
    "train_trial_index": 0,
    "predicted_text": "B",
    "base64_images": [],
    "mapped_output": "a priori",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 480.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 1.0
    }
  },
  {
    "instance_id": "id65",
    "train_trial_index": 0,
    "predicted_text": "C",
    "base64_images": [],
    "mapped_output": "Reification",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 479.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  },
  {
    "instance_id": "id146",
    "train_trial_index": 0,
    "predicted_text": "D",
    "base64_images": [],
    "mapped_output": "Straw Man",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 515.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  },
  {
    "instance_id": "id131",
    "train_trial_index": 0,
    "predicted_text": "D",
    "base64_images": [],
    "mapped_output": "Questionable Cause",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 473.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  },
  {
    "instance_id": "id168",
    "train_trial_index": 0,
    "predicted_text": "D",
    "base64_images": [],
    "mapped_output": "using threats of harm instead of reasoning to get agreement",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 505.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  },
  {
    "instance_id": "id116",
    "train_trial_index": 0,
    "predicted_text": "C",
    "base64_images": [],
    "mapped_output": "Begging the question",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 460.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  },
  {
    "instance_id": "id38",
    "train_trial_index": 0,
    "predicted_text": "C",
    "base64_images": [],
    "mapped_output": "Appeal to the masses",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 468.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 1.0
    }
  },
  {
    "instance_id": "id159",
    "train_trial_index": 0,
    "predicted_text": "C",
    "base64_images": [],
    "mapped_output": "arguing that a claim should be accepted based on evidence that is not presented, but is asserted to be well known or obvious.",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 531.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 1.0
    }
  },
  {
    "instance_id": "id154",
    "train_trial_index": 0,
    "predicted_text": "D",
    "base64_images": [],
    "mapped_output": "Appeal to ignorance",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 475.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  },
  {
    "instance_id": "id10",
    "train_trial_index": 0,
    "predicted_text": "A",
    "base64_images": [],
    "mapped_output": "characterizing an opponent's position in such a way to make it or its consequences appear to be ridiculous",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 512.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 1.0
    }
  },
  {
    "instance_id": "id23",
    "train_trial_index": 0,
    "predicted_text": "D",
    "base64_images": [],
    "mapped_output": "leads to a valid conclusion",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 473.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  },
  {
    "instance_id": "id134",
    "train_trial_index": 0,
    "predicted_text": "D",
    "base64_images": [],
    "mapped_output": "Conditional",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 472.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  },
  {
    "instance_id": "id139",
    "train_trial_index": 0,
    "predicted_text": "D",
    "base64_images": [],
    "mapped_output": "Not sufficiently similar in relevant ways",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 464.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 1.0
    }
  },
  {
    "instance_id": "id149",
    "train_trial_index": 0,
    "predicted_text": "C",
    "base64_images": [],
    "mapped_output": "Appeal to Authority",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 578.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  },
  {
    "instance_id": "id42",
    "train_trial_index": 0,
    "predicted_text": "D",
    "base64_images": [],
    "mapped_output": "argument against the person",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 463.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 1.0
    }
  },
  {
    "instance_id": "id102",
    "train_trial_index": 0,
    "predicted_text": "B",
    "base64_images": [],
    "mapped_output": "a categorical syllogism",
    "stats": {
      "num_train_trials": 1.0,
      "num_prompt_tokens": 490.0,
      "num_output_tokens": 1.0,
      "num_train_instances": 5.0,
      "prompt_truncated": 0.0,
      "exact_match": 0.0
    }
  }
]