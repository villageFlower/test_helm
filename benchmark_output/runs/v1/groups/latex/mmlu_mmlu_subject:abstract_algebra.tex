\begin{table*}[htp]
\resizebox{\textwidth}{!}{
\begin{tabular}{lrrrrrrrrr}
\toprule
Model/adapter & EM & EM (Robustness) & EM (Fairness) & # eval & # train & truncated & # prompt tokens & # output tokens & # trials \\
\midrule
Together AI Llama 3 (8B) & 0.4117647058823529 & 0.4117647058823529 & 0.4117647058823529 & 17.0 & 5.0 &  & 413.3529411764706 & 1.0 & 1.0 \\
Together AI Llama 3 (70B) & 0.5294117647058824 & 0.5294117647058824 & 0.5294117647058824 & 17.0 & 5.0 &  & 413.3529411764706 & 1.0 & 1.0 \\
Groq LLaMA 3 (8B) & 0.29411764705882354 & 0.29411764705882354 & 0.29411764705882354 & 17.0 & 5.0 &  & 413.3529411764706 & 2.1176470588235294 & 1.0 \\
Groq LLaMA 3 (70B) & 0.35294117647058826 & 0.35294117647058826 & 0.35294117647058826 & 17.0 & 5.0 &  & 413.3529411764706 & 1.0 & 1.0 \\
Hugging face LLaMA 3 (8B)(original) & 0.35294117647058826 & 0.35294117647058826 & 0.35294117647058826 & 17.0 & 5.0 &  & 369.3529411764706 & 1.0 & 1.0 \\
\bottomrule
\end{tabular}}
\caption{Results for mmlu_subject:abstract_algebra (mmlu)}
\label{fig:mmlu_subject:abstract_algebra (mmlu)}
\end{table*}