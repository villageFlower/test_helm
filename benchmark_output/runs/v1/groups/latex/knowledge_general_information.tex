\begin{table*}[htp]
\resizebox{\textwidth}{!}{
\begin{tabular}{lrrrrrr}
\toprule
Model/adapter & MMLU - # eval & MMLU - # train & MMLU - truncated & MMLU - # prompt tokens & MMLU - # output tokens & MMLU - # trials \\
\midrule
Together AI Llama 3 (8B) & 17.859649122807017 & 4.946393762183236 &  & 624.5755288203309 & 1.0 & 1.0 \\
Together AI Llama 3 (70B) & 17.859649122807017 & 4.946393762183236 &  & 624.5755288203309 & 1.0 & 1.0 \\
Groq LLaMA 3 (8B) & 17.859649122807017 & 5.0 &  & 650.7295249216954 & 1.4342029825164908 & 1.0 \\
Groq LLaMA 3 (70B) & 17.836363636363636 & 5.0 &  & 596.9089504956688 & 1.0010101010101011 & 1.0 \\
Hugging face LLaMA 3 (8B)(original) & 17.859649122807017 & 4.948343079922027 &  & 581.4741642979137 & 1.0 & 1.0 \\
\bottomrule
\end{tabular}}
\caption{Results for general_information (knowledge)}
\label{fig:general_information (knowledge)}
\end{table*}